{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GPU mátrix szorzás\n",
        "\n",
        "GPU-s dolgokat elég macerás telepíteni, a Cuda eleve csak Nvidia kártyákra van, ezért [Google Colabban](https://colab.research.google.com/) futtattam ezeket a kódokat.\n",
        "\n",
        "Ekkor szükséges az alábbi beállítás: *Futtatókörnyezet/Futtatókörnyezet módosítása/Hardveres gyorsítás: GPU*"
      ],
      "metadata": {
        "id": "qU2qytIdzGL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ivJQJVr8ykiH"
      },
      "outputs": [],
      "source": [
        "\"\"\"Könyvtárak importálása\"\"\"\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from numba import cuda, float32\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Mátrixok létrehozása\"\"\"\n",
        "\n",
        "n = 256\n",
        "a = np.random.random((n, n)).astype(np.float32)\n",
        "b = np.random.random((n, n)).astype(np.float32)\n",
        "c = np.zeros((n, n), dtype=np.float32)"
      ],
      "metadata": {
        "id": "xBOz4bevzDRT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"CPU Referencia: numpy.matmul\"\"\"\n",
        "\n",
        "%timeit np.matmul(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YljmQn9L0Egz",
        "outputId": "22e72134-4aa4-4d3a-fd0e-108a5e646d14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.39 ms ± 491 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"GPU szorzás Tensorflow segítségével\"\"\"\n",
        "\n",
        "# tömbök átmásolása GPU-ra\n",
        "a_tensor = tf.constant(a)\n",
        "b_tensor = tf.constant(b)\n",
        "\n",
        "# mátrixszorzás beépített paranccsal\n",
        "c_tensor = tf.matmul(a_tensor, b_tensor)\n",
        "%timeit tf.matmul(a_tensor, b_tensor)\n",
        "\n",
        "# visszamásolás memóriába\n",
        "c = c_tensor.numpy()  # Ez sokáig tarthat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IsITgm40T1h",
        "outputId": "b41376e2-b365-433e-f297-15e1415e0fa3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121 µs ± 39.8 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"GPU szorzás CUDA-val (nem saját kód)\"\"\"\n",
        "# forráskód: https://numba.readthedocs.io/en/stable/cuda/examples.html\n",
        "\n",
        "# Controls threads per block and shared memory usage.\n",
        "# The computation will be done on blocks of TPBxTPB elements.\n",
        "# TPB should not be larger than 32 in this example\n",
        "TPB = 32\n",
        "\n",
        "@cuda.jit\n",
        "def fast_matmul(A, B, C):\n",
        "    # Define an array in the shared memory\n",
        "    # The size and type of the arrays must be known at compile time\n",
        "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    bpg = cuda.gridDim.x    # blocks per grid\n",
        "\n",
        "    # Each thread computes one element in the result matrix.\n",
        "    # The dot product is chunked into dot products of TPB-long vectors.\n",
        "    tmp = float32(0.)\n",
        "    for i in range(bpg):\n",
        "        # Preload data into shared memory\n",
        "        sA[ty, tx] = 0\n",
        "        sB[ty, tx] = 0\n",
        "        if y < A.shape[0] and (tx + i * TPB) < A.shape[1]:\n",
        "            sA[ty, tx] = A[y, tx + i * TPB]\n",
        "        if x < B.shape[1] and (ty + i * TPB) < B.shape[0]:\n",
        "            sB[ty, tx] = B[ty + i * TPB, x]\n",
        "\n",
        "        # Wait until all threads finish preloading\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Computes partial product on the shared memory\n",
        "        for j in range(TPB):\n",
        "            tmp += sA[ty, j] * sB[j, tx]\n",
        "\n",
        "        # Wait until all threads finish computing\n",
        "        cuda.syncthreads()\n",
        "    if y < C.shape[0] and x < C.shape[1]:\n",
        "        C[y, x] = tmp"
      ],
      "metadata": {
        "id": "Qnt1luoP1Hpv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tömbök átmásolása GPU-ra\n",
        "a_d = cuda.to_device(a)\n",
        "b_d = cuda.to_device(b)\n",
        "c_d = cuda.to_device(c)\n",
        "\n",
        "# A GPU thredjeinek Blockokba és Gridekbe osztása\n",
        "threadsperblock = (TPB, TPB)\n",
        "blockspergrid_x = math.ceil(c.shape[0] / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(c.shape[1] / threadsperblock[1])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# mátrixszorzás\n",
        "%timeit fast_matmul[blockspergrid, threadsperblock](a_d, b_d, c_d)\n",
        "\n",
        "# visszamásolás memóriába\n",
        "c = c_d.copy_to_host()  # Ez sokáig tarthat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C3cyB223DIu",
        "outputId": "3d6b5f6a-798d-40e5-ab9f-e6304357bea9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87.6 µs ± 43.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eredmények\n",
        "A GPU-s esetben igen nagy a szórás. Néha nagyságrendekkel tovább tart. Nagy méretnél a tömbök átmásolása jóval hosszabb idő, mint maga a szorzás.\n",
        "\n",
        "\n",
        "| n     \t| Numpy   \t| Tensorflow \t| Cuda    \t|\n",
        "|-------\t|---------\t|------------\t|---------\t|\n",
        "| 256   \t| 547 µs  \t| 83.7 µs    \t| 53 µs   \t|\n",
        "| 1024  \t| 32.1 ms \t| 78.1 µs    \t| 69.9 µs \t|\n",
        "| 4096  \t| 2.05 s  \t| 103 µs     \t| 52.9 µs \t|\n",
        "| 16384 \t| 124 s   \t| 218 µs     \t| 84.4 µs \t|"
      ],
      "metadata": {
        "id": "yKRGa5pv3xGx"
      }
    }
  ]
}